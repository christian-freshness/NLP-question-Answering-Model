{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the wikipedia API for extracting the data from wikipedia\n",
    "\n",
    "import wikipedia\n",
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting different articles about all 46 United States Presidents from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'William Jefferson Clinton (né Blythe III; born August 19, 1946) is an American politician and attorney who served as the 42nd president of the United States from 1993 to 2001. He previously served as governor of Arkansas from 1979 to 1981 and again from 1983 to 1992, and as attorney general of Arkansas from 1977 to 1979. A member of the Democratic party, Clinton became known as a New Democrat, as many of his policies reflected a centrist \"Third Way\" political philosophy. He is the husband of Hillary Clinton, who was secretary of state from 2009 to 2013 and the Democratic nominee for president in the 2016 presidential election.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_1 = wikipedia.summary(\"bill Clinton\", sentences=4)\n",
    "context_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Warren Gamaliel Harding (November 2, 1865 – August 2, 1923) was the 29th president of the United States, serving from 1921 until his death in 1923. A member of the Republican Party, he was one of the most popular U.S. presidents to that point. After his death, a number of scandals, including Teapot Dome, came to light, as did his extramarital affair with Nan Britton; those eroded his popular regard.\\nHarding lived in rural Ohio all his life, except when political service took him elsewhere. As a young man, he bought The Marion Star and built it into a successful newspaper. He served in the Ohio State Senate from 1900 to 1904, then as lieutenant governor for two years. He was defeated for governor in 1910, but was elected to the United States Senate in 1914, the state's first direct election for that office. He ran for the Republican nomination for president in 1920, and was considered a long shot until after the convention began. The leading candidates could not gain the needed majority, and the convention deadlocked. Harding's support gradually grew until he was nominated on the tenth ballot.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_2 = wikipedia.summary(\"Warren G. Harding\", sentences=10)\n",
    "context_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ronald Wilson Reagan ( RAY-gən; February 6, 1911 – June 5, 2004) was an American politician who served as the 40th president of the United States from 1981 to 1989 and became a highly influential voice of modern conservatism. Prior to his presidency, he was a Hollywood movie actor and union leader before serving as the 33rd governor of California from 1967 to 1975.\\nRaised in a low-income family in small towns of northern Illinois, Reagan graduated from Eureka College in 1932 and worked as a radio sports commentator. After moving to California in 1937, he found work as an actor and starred in a few major productions. As president of the Screen Actors Guild, Reagan worked to root out alleged communist influence. In the 1950s, he moved into television and was a motivational speaker at General Electric factories. In 1964, his speech \"A Time for Choosing\" earned him national attention as a new conservative spokesman. Building a network of supporters, Reagan was elected governor of California in 1966. As governor, he raised taxes, turned a state budget deficit to a surplus, challenged the protesters at UC Berkeley, and ordered in National Guard troops during a period of protest movements.\\nIn 1980, Reagan won the Republican presidential nomination and defeated the incumbent president, Jimmy Carter.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_3 = wikipedia.summary(\"Ronald Reagan\", sentences=11)\n",
    "context_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Hussein Obama II ( (listen) bə-RAHK hoo-SAYN oh-BAH-mə; born August 4, 1961) is an American politician, author, and retired attorney who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party, Obama was the first African-American  president of the United States. He previously served as a U.S. senator from Illinois from 2005 to 2008 and as an Illinois state senator from 1997 to 2004. Outside of politics, Obama has published three bestselling books; Dreams from My Father (1995), The Audacity of Hope (2006) and A Promised Land (2020).Obama was born in Honolulu, Hawaii. After graduating from Columbia University in 1983, he worked as a community organizer in Chicago. In 1988, he enrolled in Harvard Law School, where he was the first black president of the Harvard Law Review. After graduating, he became a civil rights attorney and an academic, teaching constitutional law at the University of Chicago Law School from 1992 to 2004. Turning to elective politics, he represented the 13th district in the Illinois Senate from 1997 until 2004, when he ran for the U.S. Senate. Obama received national attention in 2004 with his March Senate primary win, his well-received July Democratic National Convention keynote address, and his landslide November election to the Senate. In 2008, a year after beginning his campaign, and after a close primary campaign against Hillary Clinton, he was nominated by the Democratic Party for president.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_4 = wikipedia.summary(\"Barack Obama\", sentences=11)\n",
    "context_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'William Henry Harrison (February 9, 1773 – April 4, 1841) was an American military officer and politician who served as the ninth president of the United States for 31 days in 1841, becoming the first president to die in office and the shortest-serving U.S. president in history. His death sparked a brief constitutional crisis regarding succession to the presidency, as at the time the U.S. Constitution did not make it entirely clear what should be done in the event of a president\\'s death. \\nHarrison was born in Charles City County, Virginia. He was a son of Founding Father Benjamin Harrison V and the paternal grandfather of Benjamin Harrison, the 23rd president of the United States. Harrison was the last president born as a British subject in the Thirteen Colonies. During his early military career, he participated in the 1794 Battle of Fallen Timbers, an American military victory that effectively ended the Northwest Indian War. Later, he led a military force against Tecumseh\\'s confederacy at the Battle of Tippecanoe in 1811, where he earned the nickname \"Old Tippecanoe\". He was promoted to major general in the Army in the War of 1812, and in 1813 led American infantry and cavalry at the Battle of the Thames in Upper Canada.Harrison began his political career in 1798, when he was appointed Secretary of the Northwest Territory, and in 1799 he was elected as the territory\\'s delegate in the House of Representatives. Two years later, he became governor of the newly established Indiana Territory, a post he held until 1812. After the War of 1812, he moved to Ohio where he was elected to represent the state\\'s 1st district in the House in 1816.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_5 = wikipedia.summary(\"William Henry Harrison\", sentences=11)\n",
    "context_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is a list of presidents of the United States by time in office. The listed number of days is calculated as the difference between dates, which counts the number of calendar days except the last day. The length of a full four-year presidential term of office usually amounts to 1,461 days (three common years of 365 days plus one leap year of 366 days). If the last day is included, all numbers would be one day more, except Grover Cleveland would have two more days, as he served two non-consecutive terms.Of the individuals elected President of the United States, four died of natural causes while in office (William Henry Harrison, Zachary Taylor, Warren G. Harding and Franklin D. Roosevelt), four were assassinated (Abraham Lincoln, James A. Garfield, William McKinley and John F. Kennedy) and one resigned from office (Richard Nixon).William Henry Harrison spent the shortest time in office, while Franklin D. Roosevelt spent the longest. Roosevelt is the only American president to have served more than two terms. Following ratification of the Twenty-second Amendment in 1951, presidents—beginning with Dwight D. Eisenhower—have been ineligible for election to a third term or, after serving more than two years of a term to which some other person was elected president, to a second term. The amendment contained a grandfather clause that explicitly exempted the incumbent president, then Harry S. Truman, from the new term limitations.\\nGrover Cleveland was the only president to leave office and return for a second term four years later. Consequently, while there have been 46 presidencies in the nation's history, only 45 people have been sworn into office (as Cleveland is numbered as both the 22nd and 24th president).\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_6 = wikipedia.summary(\"List of presidents of the United States by time in office\", sentences=11)\n",
    "context_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a list of presidents of the United States by age. The first table charts the age of each United States president at the time of presidential inauguration (first inauguration if elected to multiple and consecutive terms), upon leaving office, and at the time of death. Where the president is still living, their lifespan is calculated up to September 29, 2021.\\n\\n\\n== Age of presidents ==\\n\\nThe median age at inauguration of incoming U.S. presidents is 55 years. The specific years and days median is 55 years and 355 days, which falls midway between how old Grover Cleveland was in 1893 and Richard Nixon was in 1969.\\nThe youngest person to assume the presidency was Theodore Roosevelt, who, at the age of 42, succeeded to the office after the assassination of William McKinley. The youngest to become president by election was John F. Kennedy, who was inaugurated at age 43. The oldest person to assume the presidency was Joe Biden, who took the presidential oath of office two months after turning 78.Assassinated at age 46, John F. Kennedy was the youngest president at the end of his tenure, and his lifespan was the shortest of any president. At age 50, Theodore Roosevelt was the youngest person to become a former president. The oldest president at the end of his tenure was Ronald Reagan at 77; this distinction will eventually devolve upon Joe Biden, who was older when he took office than Reagan was when he left office.The president born after the greatest number of his successors is John F. Kennedy.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_7 = wikipedia.summary(\"Age of presidents\", sentences=11)\n",
    "context_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\",return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n",
      "C:\\Users\\AJULOR FRESH\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Some layers from the model checkpoint at distilbert-base-cased-distilled-squad were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased-distilled-squad and are newly initialized: ['dropout_92']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# importing pipeline from transformers\n",
    "# importing the pre-trained \"distilbert-base-cased-distilled-squad\" model from huggingface\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"question-answering\") # model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing sample questions with pipelines directly without tokenizing the texts, Using the pre-trained \"distilbert-base-cased-distilled-squad\" model from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = context_1 + context_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Who was the US president in 1923?\n",
      "ANSWER: {'score': 0.9719240069389343, 'start': 634, 'end': 657, 'answer': 'Warren Gamaliel Harding'}\n",
      "\n",
      "QUESTION: When was warren defeated as a governor?\n",
      "ANSWER: {'score': 0.9815115332603455, 'start': 1342, 'end': 1346, 'answer': '1910'}\n",
      "\n",
      "QUESTION: Who was the 29th president\n",
      "ANSWER: {'score': 0.9748360514640808, 'start': 634, 'end': 657, 'answer': 'Warren Gamaliel Harding'}\n",
      "\n",
      "QUESTION: In what year was Bill Clinton born?\n",
      "ANSWER: {'score': 0.9486518502235413, 'start': 58, 'end': 62, 'answer': '1946'}\n"
     ]
    }
   ],
   "source": [
    "context = main\n",
    "\n",
    "question_1 = \"Who was the US president in 1923?\"\n",
    "question_2 = \"When was warren defeated as a governor?\"\n",
    "question_3 = \"Who was the 29th president\"\n",
    "question_4 = \"In what year was Bill Clinton born?\"\n",
    "\n",
    "result = nlp(question=question_1, context=context)\n",
    "print(f\"QUESTION: {question_1}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_2, context=context)\n",
    "print(f\"QUESTION: {question_2}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_3, context=context)\n",
    "print(f\"QUESTION: {question_3}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_4, context=context)\n",
    "print(f\"QUESTION: {question_4}\")\n",
    "print(f\"ANSWER: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: what was ronald reagan's profession prior to his presidency?\n",
      "ANSWER: {'score': 0.3889077305793762, 'start': 260, 'end': 298, 'answer': 'Hollywood movie actor and union leader'}\n",
      "\n",
      "QUESTION: who did ronald reagan defeat?\n",
      "ANSWER: {'score': 0.9304869771003723, 'start': 1299, 'end': 1311, 'answer': 'Jimmy Carter'}\n",
      "\n",
      "QUESTION: who was the 40th president?\n",
      "ANSWER: {'score': 0.9943492412567139, 'start': 0, 'end': 20, 'answer': 'Ronald Wilson Reagan'}\n",
      "\n",
      "QUESTION: when was ronald reagan born?\n",
      "ANSWER: {'score': 0.8251843452453613, 'start': 32, 'end': 48, 'answer': 'February 6, 1911'}\n"
     ]
    }
   ],
   "source": [
    "context = context_3\n",
    "\n",
    "question_1 = \"what was ronald reagan's profession prior to his presidency?\"\n",
    "question_2 = \"who did ronald reagan defeat?\"\n",
    "question_3 = \"who was the 40th president?\"\n",
    "question_4 = \"when was ronald reagan born?\"\n",
    "\n",
    "result = nlp(question=question_1, context=context)\n",
    "print(f\"QUESTION: {question_1}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_2, context=context)\n",
    "print(f\"QUESTION: {question_2}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_3, context=context)\n",
    "print(f\"QUESTION: {question_3}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_4, context=context)\n",
    "print(f\"QUESTION: {question_4}\")\n",
    "print(f\"ANSWER: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: First president who was African-American.?\n",
      "ANSWER: {'score': 0.4093586206436157, 'start': 0, 'end': 20, 'answer': 'Barack Hussein Obama'}\n",
      "\n",
      "QUESTION: what are the best selling books of obama?\n",
      "ANSWER: {'score': 0.026139752939343452, 'start': 506, 'end': 556, 'answer': 'Dreams from My Father (1995), The Audacity of Hope'}\n",
      "\n",
      "QUESTION: where was obama born?\n",
      "ANSWER: {'score': 0.8348367214202881, 'start': 609, 'end': 625, 'answer': 'Honolulu, Hawaii'}\n",
      "\n",
      "QUESTION: what obama receive national attention for in 2004?\n",
      "ANSWER: {'score': 0.11424309015274048, 'start': 1132, 'end': 1207, 'answer': 'Obama received national attention in 2004 with his March Senate primary win'}\n"
     ]
    }
   ],
   "source": [
    "context = context_4\n",
    "\n",
    "question_1 = \"First president who was African-American.?\"\n",
    "question_2 = \"what are the best selling books of obama?\"\n",
    "question_3 = \"where was obama born?\"\n",
    "question_4 = \"what obama receive national attention for in 2004?\"\n",
    "\n",
    "result = nlp(question=question_1, context=context)\n",
    "print(f\"QUESTION: {question_1}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_2, context=context)\n",
    "print(f\"QUESTION: {question_2}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_3, context=context)\n",
    "print(f\"QUESTION: {question_3}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_4, context=context)\n",
    "print(f\"QUESTION: {question_4}\")\n",
    "print(f\"ANSWER: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Who was the first US president to die in office?\n",
      "ANSWER: {'score': 0.9922813773155212, 'start': 0, 'end': 22, 'answer': 'William Henry Harrison'}\n",
      "\n",
      "QUESTION: who was the last president born as a British?\n",
      "ANSWER: {'score': 0.07171846926212311, 'start': 630, 'end': 647, 'answer': 'Benjamin Harrison'}\n",
      "\n",
      "QUESTION: where was he born?\n",
      "ANSWER: {'score': 0.9332588315010071, 'start': 515, 'end': 544, 'answer': 'Charles City County, Virginia'}\n"
     ]
    }
   ],
   "source": [
    "context = context_5\n",
    "\n",
    "question_1 = \"Who was the first US president to die in office?\"\n",
    "question_2 = \"who was the last president born as a British?\"\n",
    "question_3 = \"where was he born?\"\n",
    "\n",
    "result = nlp(question=question_1, context=context)\n",
    "print(f\"QUESTION: {question_1}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_2, context=context)\n",
    "print(f\"QUESTION: {question_2}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_3, context=context)\n",
    "print(f\"QUESTION: {question_3}\")\n",
    "print(f\"ANSWER: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Who was the only president to leave office and return for a second term four years later?\n",
      "ANSWER: {'score': 0.9820696115493774, 'start': 1450, 'end': 1466, 'answer': 'Grover Cleveland'}\n",
      "\n",
      "QUESTION: who spent the shortest time in office?\n",
      "ANSWER: {'score': 0.9580665230751038, 'start': 844, 'end': 866, 'answer': 'William Henry Harrison'}\n",
      "\n",
      "QUESTION: who spent the longest?\n",
      "ANSWER: {'score': 0.4471779465675354, 'start': 908, 'end': 929, 'answer': 'Franklin D. Roosevelt'}\n",
      "\n",
      "QUESTION: who is the only American president to have served more than two terms?\n",
      "ANSWER: {'score': 0.19604936242103577, 'start': 949, 'end': 958, 'answer': 'Roosevelt'}\n",
      "\n",
      "QUESTION: how many presidents died of natural causes while in office?\n",
      "ANSWER: {'score': 0.8451042175292969, 'start': 570, 'end': 574, 'answer': 'four'}\n"
     ]
    }
   ],
   "source": [
    "context = context_6\n",
    "\n",
    "question_1 = \"Who was the only president to leave office and return for a second term four years later?\"\n",
    "question_2 = \"who spent the shortest time in office?\"\n",
    "question_3 = \"who spent the longest?\"\n",
    "question_4 = \"who is the only American president to have served more than two terms?\"\n",
    "question_5 = \"how many presidents died of natural causes while in office?\"\n",
    "\n",
    "result = nlp(question=question_1, context=context)\n",
    "print(f\"QUESTION: {question_1}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_2, context=context)\n",
    "print(f\"QUESTION: {question_2}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_3, context=context)\n",
    "print(f\"QUESTION: {question_3}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_4, context=context)\n",
    "print(f\"QUESTION: {question_4}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_5, context=context)\n",
    "print(f\"QUESTION: {question_5}\")\n",
    "print(f\"ANSWER: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Who was the youngest person to assume the presidency?\n",
      "ANSWER: {'score': 0.17534761130809784, 'start': 672, 'end': 690, 'answer': 'Theodore Roosevelt'}\n",
      "\n",
      "QUESTION: who was the youngest to become president by election?\n",
      "ANSWER: {'score': 0.940102219581604, 'start': 833, 'end': 848, 'answer': 'John F. Kennedy'}\n",
      "\n",
      "QUESTION: who was the oldest person to assume the presidency?\n",
      "ANSWER: {'score': 0.6594648957252502, 'start': 928, 'end': 937, 'answer': 'Joe Biden'}\n",
      "\n",
      "QUESTION: who was the oldest president at the end of his tenure?\n",
      "ANSWER: {'score': 0.20578505098819733, 'start': 1287, 'end': 1300, 'answer': 'Ronald Reagan'}\n"
     ]
    }
   ],
   "source": [
    "context = context_7\n",
    "\n",
    "question_1 = \"Who was the youngest person to assume the presidency?\"\n",
    "question_2 = \"who was the youngest to become president by election?\"\n",
    "question_3 = \"who was the oldest person to assume the presidency?\"\n",
    "question_4 = \"who was the oldest president at the end of his tenure?\"\n",
    "\n",
    "result = nlp(question=question_1, context=context)\n",
    "print(f\"QUESTION: {question_1}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_2, context=context)\n",
    "print(f\"QUESTION: {question_2}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_3, context=context)\n",
    "print(f\"QUESTION: {question_3}\")\n",
    "print(f\"ANSWER: {result}\")\n",
    "print('')\n",
    "result = nlp(question=question_4, context=context)\n",
    "print(f\"QUESTION: {question_4}\")\n",
    "print(f\"ANSWER: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensorflow Autotokenizer to tokenize the texts and applying the \"bert-large-uncased-whole-word-masking-finetuned-squad\" model to answer sample questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the US president in 1923?\n",
      "Answer: warren gamaliel harding\n",
      "\n",
      "Question: When was warren defeated as a governor?\n",
      "Answer: 1910\n",
      "\n",
      "Question: Who was the 29th president\n",
      "Answer: warren gamaliel harding\n",
      "\n",
      "Question: In what year was Bill Clinton born?\n",
      "Answer: 1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = main\n",
    "\n",
    "questions = [\n",
    "    \"Who was the US president in 1923?\",\n",
    "    \"When was warren defeated as a governor?\",\n",
    "    \"Who was the 29th president\",\n",
    "    \"In what year was Bill Clinton born?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(inputs)\n",
    "\n",
    "    answer_start = tf.argmax(\n",
    "      answer_start_scores, axis=1\n",
    "    ).numpy()[0]  # this Gets the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = (\n",
    "        tf.argmax(answer_end_scores, axis=1) + 1\n",
    "    ).numpy()[0]  # this Gets the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what was ronald reagan's profession prior to his presidency?\n",
      "Answer: hollywood movie actor\n",
      "\n",
      "Question: who did ronald reagan defeat?\n",
      "Answer: jimmy carter\n",
      "\n",
      "Question: who was the 40th president?\n",
      "Answer: ronald wilson reagan\n",
      "\n",
      "Question: when was ronald reagan born?\n",
      "Answer: february 6, 1911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = context_3\n",
    "\n",
    "questions = [\n",
    "    \"what was ronald reagan's profession prior to his presidency?\",\n",
    "    \"who did ronald reagan defeat?\",\n",
    "    \"who was the 40th president?\",\n",
    "    \"when was ronald reagan born?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(inputs)\n",
    "\n",
    "    answer_start = tf.argmax(\n",
    "      answer_start_scores, axis=1\n",
    "    ).numpy()[0]  # this Gets the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = (\n",
    "        tf.argmax(answer_end_scores, axis=1) + 1\n",
    "    ).numpy()[0]  # this Gets the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: First president who was African-American.?\n",
      "Answer: obama was the first african - american president of the united states\n",
      "\n",
      "Question: what are the best selling books of obama?\n",
      "Answer: dreams from my father ( 1995 ), the audacity of hope ( 2006 ) and a promised land ( 2020 )\n",
      "\n",
      "Question: where was obama born?\n",
      "Answer: honolulu, hawaii\n",
      "\n",
      "Question: what obama receive national attention for in 2004?\n",
      "Answer: his march senate primary win, his well - received july democratic national convention keynote address, and his landslide november election to the senate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = context_4\n",
    "\n",
    "questions = [\n",
    "    \"First president who was African-American.?\",\n",
    "    \"what are the best selling books of obama?\",\n",
    "    \"where was obama born?\",\n",
    "    \"what obama receive national attention for in 2004?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(inputs)\n",
    "\n",
    "    answer_start = tf.argmax(\n",
    "      answer_start_scores, axis=1\n",
    "    ).numpy()[0]  # this Gets the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = (\n",
    "        tf.argmax(answer_end_scores, axis=1) + 1\n",
    "    ).numpy()[0]  # this Gets the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the first US president to die in office?\n",
      "Answer: william henry harrison\n",
      "\n",
      "Question: who was the last president born as a British?\n",
      "Answer: william henry harrison\n",
      "\n",
      "Question: where was he born?\n",
      "Answer: charles city county, virginia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = context_5\n",
    "\n",
    "questions = [\n",
    "    \"Who was the first US president to die in office?\",\n",
    "    \"who was the last president born as a British?\",\n",
    "    \"where was he born?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(inputs)\n",
    "\n",
    "    answer_start = tf.argmax(\n",
    "      answer_start_scores, axis=1\n",
    "    ).numpy()[0]  # this Gets the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = (\n",
    "        tf.argmax(answer_end_scores, axis=1) + 1\n",
    "    ).numpy()[0]  # this Gets the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the only president to leave office and return for a second term four years later?\n",
      "Answer: grover cleveland\n",
      "\n",
      "Question: who spent the shortest time in office?\n",
      "Answer: william henry harrison\n",
      "\n",
      "Question: who spent the longest?\n",
      "Answer: franklin d. roosevelt\n",
      "\n",
      "Question: who is the only American president to have served more than two terms?\n",
      "Answer: franklin d. roosevelt\n",
      "\n",
      "Question: how many presidents died of natural causes while in office?\n",
      "Answer: four\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = context_6\n",
    "\n",
    "questions = [\n",
    "    \"Who was the only president to leave office and return for a second term four years later?\",\n",
    "    \"who spent the shortest time in office?\",\n",
    "    \"who spent the longest?\",\n",
    "    \"who is the only American president to have served more than two terms?\",\n",
    "    \"how many presidents died of natural causes while in office?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(inputs)\n",
    "\n",
    "    answer_start = tf.argmax(\n",
    "      answer_start_scores, axis=1\n",
    "    ).numpy()[0]  # this Gets the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = (\n",
    "        tf.argmax(answer_end_scores, axis=1) + 1\n",
    "    ).numpy()[0]  # this Gets the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the youngest person to assume the presidency?\n",
      "Answer: theodore roosevelt\n",
      "\n",
      "Question: who was the youngest to become president by election?\n",
      "Answer: john f. kennedy\n",
      "\n",
      "Question: who was the oldest person to assume the presidency?\n",
      "Answer: joe biden\n",
      "\n",
      "Question: who was the oldest president at the end of his tenure?\n",
      "Answer: ronald reagan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = context_7\n",
    "\n",
    "questions = [\n",
    "    \"Who was the youngest person to assume the presidency?\",\n",
    "    \"who was the youngest to become president by election?\",\n",
    "    \"who was the oldest person to assume the presidency?\",\n",
    "    \"who was the oldest president at the end of his tenure?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(inputs)\n",
    "\n",
    "    answer_start = tf.argmax(\n",
    "      answer_start_scores, axis=1\n",
    "    ).numpy()[0]  # this Gets the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = (\n",
    "        tf.argmax(answer_end_scores, axis=1) + 1\n",
    "    ).numpy()[0]  # this Gets the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both models performed well\n",
    "### The best results gotten was when we used a tokenizer and the \"bert-large-uncased-whole-word-masking-finetuned-squad\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
